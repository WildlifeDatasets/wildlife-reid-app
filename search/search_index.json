{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#the-wildlife-reid-app-application","title":"The WildLife ReID App application","text":"<p>The application is created to help categorize images according to the species and identify animals in camera trap images. Here are some useful links to get you started:</p> <ol> <li>I want to classify species in media files</li> <li>I want to identify individuals in media files</li> <li>I want to go to the CWildLife ReID Application</li> <li>I want to install the application</li> <li>I want to contact the developers</li> </ol>"},{"location":"#what-is-wildlife-reid-app","title":"What is WildLife ReID App?","text":"<p>The WildLife ReID App is a web-based tool designed to assist researchers and wildlife enthusiasts in classifying and identifying carnivorous animals captured in camera trap images. The application leverages advanced machine learning algorithms to automate the process of species classification and individual identification, making it easier for users to analyze large datasets of wildlife images.</p> <p>The two main usage scenarios are:</p> <ul> <li>Taxon classification - the user can classify images according to the species</li> <li>Individuality re-identification - the user can identify individuals in the images</li> </ul> <p>Go to first steps with the application to learn more.</p>"},{"location":"#about-the-project","title":"About the project","text":"<p>The project aims to research and develop new technologies related to a deep understanding of data from camera traps. The technology will greatly increase annotation effectivity, will help to reduce reaction time to urgent situations, e.g. the occurrence of a conflict species in new areas or a harmed animal, will help to improve and simplify the identification of the individuals and to refine population estimates of endangered species, and will help to find new relations in the indexed data across time and diverse locations. The developed methods and tools will improve the monitoring of invasive species. The technologies will streamline activities of public administration, namely AOPK \u010cR responsible for reporting species status according to Art. 17 of Habitats Directive (92/43/EEC).</p>"},{"location":"#funding","title":"Funding","text":"<p>The project is funded by the Technology Agency of the Czech Republic (TA\u010cR) under the project number SS05010008-V9.</p>"},{"location":"architecture/","title":"System Architecture","text":"<p>The Wildlife ReID App is built as a microservices application orchestrated using Docker Compose. It separates the user-facing web interface from the resource-intensive machine learning tasks required for image analysis.</p>"},{"location":"architecture/#high-level-overview","title":"High-Level Overview","text":"<p>The system consists of three main logic components: 1.  API (Django): Handles user interactions, data management, and orchestration. 2.  Taxon Worker: Performs species classification (ML inference). 3.  Identification Worker: Performs individual re-identification (ML inference).</p> <p>These components communicate asynchronously via a message broker (RabbitMQ) and share data through a database and file storage.</p>"},{"location":"architecture/#service-components","title":"Service Components","text":""},{"location":"architecture/#1-web-api-api","title":"1. Web API (<code>api</code>)","text":"<ul> <li>Technology: Python, Django, Django REST Framework.</li> <li>Role:<ul> <li>Serves the web frontend and REST API.</li> <li>Manages user authentication (including OAuth).</li> <li>Handles file uploads.</li> <li>Dispatches tasks to workers via Celery.</li> </ul> </li> <li>Dependencies: Connects to the Main Database, Redis, and RabbitMQ.</li> </ul>"},{"location":"architecture/#2-workers","title":"2. Workers","text":"<p>These services run in the background, typically on hardware with GPU acceleration.</p> <ul> <li>Taxon Worker (<code>taxon_worker</code>):<ul> <li>Receives images from the queue.</li> <li>Classifies the species/taxon of the animal in the image.</li> <li>Returns the classification result to the API.</li> </ul> </li> <li>Identification Worker (<code>identification_worker</code>):<ul> <li>Receives cropped images of specific individuals.</li> <li>Computes embeddings (feature vectors) to identify unique individuals.</li> <li>Uses its own dedicated database (<code>identification_worker_db</code>) to store vector embeddings for fast retrieval.</li> </ul> </li> </ul>"},{"location":"architecture/#3-infrastructure","title":"3. Infrastructure","text":"<ul> <li>Nginx (<code>nginx</code>):<ul> <li>Acts as a reverse proxy.</li> <li>Serves static files (images, CSS, JS).</li> <li>Forwards application requests to the API container.</li> </ul> </li> <li>Message Broker (<code>broker</code>):<ul> <li>Technology: RabbitMQ.</li> <li>Distributes tasks from the API to the workers.</li> </ul> </li> <li>Cache &amp; Result Backend (<code>redis</code>):<ul> <li>Technology: Redis.</li> <li>Stores Celery task results and handles application caching.</li> </ul> </li> <li>Databases:<ul> <li>Main DB (<code>db</code>): PostgreSQL. Stores application data (users, metadata, file paths).</li> <li>Identification DB (<code>identification_worker_db</code>): PostgreSQL. Dedicated to the identification worker for efficient handling of identification data.</li> </ul> </li> </ul>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<ol> <li>Upload: A user uploads a batch of images via the Web UI.</li> <li>Storage: Images are stored in the shared volume (<code>api-data</code> or external storage).</li> <li>Task Dispatch: The API creates metadata in the Main DB and sends a classification task to the <code>broker</code>.</li> <li>Classification: The <code>taxon_worker</code> picks up the task, processes the image (GPU), and updates the classification result in the Main DB.</li> <li>Identification: If confirmed, the API sends a task to the <code>identification_worker</code>.</li> <li>Matching: The <code>identification_worker</code> compares the image against known individuals in <code>identification_worker_db</code> and returns potential matches.</li> </ol>"},{"location":"architecture/#storage-architecture","title":"Storage Architecture","text":"<p>The application uses several Docker volumes to persist data:</p> <ul> <li><code>api-data</code>: Stores uploaded media files.</li> <li><code>db-data</code>: Persists the main PostgreSQL database.</li> <li><code>identification-worker-db-data</code>: Persists the identification worker's database.</li> <li><code>caid_import</code>: A bind-mount used for importing large datasets from the local filesystem.</li> </ul>"},{"location":"build_docs/","title":"Building Documentation with MkDocs","text":"<p>Project is built automatically using MkDocs and hosted on GitHub Pages.</p>"},{"location":"build_docs/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"build_docs/#commands","title":"Commands","text":"<ul> <li><code>pdm install</code> - Install the project dependencies.</li> <li><code>pdm run mkdocs serve</code> - Start the live-reloading docs server.</li> </ul> <p>Other commands you can use:</p> <ul> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"cloud_import/","title":"Cloud import","text":""},{"location":"configuration/","title":"Configuration Guide","text":"<p>The application configuration is managed primarily through environment variables loaded from <code>.env</code> files. This allows for separation between code and configuration, making it easier to deploy across different environments (development, production).</p>"},{"location":"configuration/#environment-files","title":"Environment Files","text":"<p>The Docker Compose configuration loads variables from several sources in the following priority:</p> <ol> <li><code>.env</code> (Project root - User defined secrets)</li> <li><code>src/variables.prod.env</code> (Production defaults)</li> <li><code>src/variables.env</code> (Shared defaults)</li> <li><code>src/variables.dev.env</code> (Development overrides)</li> </ol> <p>Important: You should create a <code>.env</code> file in the root directory <code>wildlife-reid-app/</code> to store sensitive keys and local path configurations. This file is ignored by Git.</p>"},{"location":"configuration/#key-configuration-variables","title":"Key Configuration Variables","text":""},{"location":"configuration/#general-settings","title":"General Settings","text":"Variable Description Example <code>CAID_HOST</code> The hostname or IP address where the application is accessible. <code>localhost</code>, <code>192.168.1.50</code>, <code>example.com</code> <code>DEBUG</code> Enables Django debug mode. Set to <code>False</code> in production. <code>True</code> / <code>False</code> <code>TZ</code> Timezone setting for containers. <code>Europe/Prague</code>"},{"location":"configuration/#authentication-integrations","title":"Authentication &amp; Integrations","text":"Variable Description <code>ALLAUTH_GOOGLE_CLIENT_ID</code> Google OAuth Client ID for social login. <code>ALLAUTH_GOOGLE_CLIENT_SECRET</code> Google OAuth Client Secret. <code>WANDB_API_KEY</code> API Key for Weights &amp; Biases (used for experiment tracking in workers)."},{"location":"configuration/#data-storage","title":"Data &amp; Storage","text":"Variable Description <code>CAID_IMPORT</code> Local path on the host machine to mount for bulk data imports. Defaults to <code>./caid_import</code>. <code>SFTP_CMD</code> Command for mounting external storage via SSHFS (if used). <code>SFTP_PASSWORD</code> Password for the SFTP mount."},{"location":"configuration/#database-credentials","title":"Database Credentials","text":"<p>These variables control the connection to the PostgreSQL databases.</p> <ul> <li><code>POSTGRES_DB</code></li> <li><code>POSTGRES_USER</code></li> <li><code>POSTGRES_PASSWORD</code></li> <li><code>POSTGRES_HOST</code></li> <li><code>POSTGRES_PORT</code></li> </ul>"},{"location":"configuration/#worker-resources","title":"Worker Resources","text":"Variable Description <code>API_IMAGE</code> Docker image tag for the API. <code>TAXON_WORKER_IMAGE</code> Docker image tag for the Taxon Worker. <code>IDENTIFICATION_WORKER_IMAGE</code> Docker image tag for the ID Worker."},{"location":"configuration/#development-vs-production","title":"Development vs. Production","text":""},{"location":"configuration/#development-docker-composedevyml","title":"Development (<code>docker-compose.dev.yml</code>)","text":"<ul> <li>Uses <code>src/variables.dev.env</code>.</li> <li>Sets <code>DEBUG=True</code>.</li> <li>Mounts local source code directories (<code>./src/api</code>, etc.) into containers for live code updates.</li> <li>Exposes ports directly for easier debugging.</li> </ul>"},{"location":"configuration/#production-docker-composeyml","title":"Production (<code>docker-compose.yml</code>)","text":"<ul> <li>Uses <code>src/variables.prod.env</code>.</li> <li>Should have <code>DEBUG=False</code>.</li> <li>Uses built Docker images rather than local code mounts.</li> <li>Restarts containers automatically (<code>restart: always</code>).</li> </ul>"},{"location":"contact/","title":"Contact","text":"<p>The application is developed by the Department of Cybernetics at the University of West Bohemia. For more information about the project, please contact us at:</p> <ul> <li>picekl@ntis.zcu.cz</li> <li>mjirik@ntis.zcu.cz</li> </ul>"},{"location":"first_steps/","title":"Getting Started","text":"<p>User can start using the application by logging in. The application is available at https://caid.kky.zcu.cz/.</p> <p>User account can be created by the administrators, or the existing Google login via OAuth technology can be used for authentication. </p> <p>After logging in, the dashboard is displayed. There you can see the base statistic information about uploaded media files.</p> <p>The two main usage scenarios are:</p> <ul> <li>Taxon classification - the user can classify images according to the species</li> <li>Individuality re-identification - the user can identify individuals in the images</li> </ul> <p>The taxon classification is available for all users. The individual identification is available for cooperating groups and users. If you are interested in the individuality identification, contact us.</p> <p></p>"},{"location":"identification/","title":"Individual Identification","text":"<p>The Identification module is the core of the application, allowing you to recognize specific individuals (e.g., \"Lynx_01\", \"Bear_Bastien\") across different images and videos using AI-assisted matching.</p>"},{"location":"identification/#1-getting-data-into-identification","title":"1. Getting Data into Identification","text":"<p>There are two primary ways to feed data into the identification pipeline:</p>"},{"location":"identification/#a-from-taxon-classification","title":"A. From Taxon Classification","text":"<p>If you have already processed images through the Taxon Classification module, you can simply select the relevant species (e.g., Lynx lynx) and forward those files directly to the Identification module.</p>"},{"location":"identification/#b-direct-upload","title":"B. Direct Upload","text":"<p>You can upload data directly if you already have files sorted or if you are importing an existing dataset.</p>"},{"location":"identification/#option-1-unorganized-imagesvideos-new-individuals","title":"Option 1: Unorganized Images/Videos (New Individuals)","text":"<p>If you have a batch of images and don't know who is who, upload a simple ZIP file. You will assign identities manually in the web interface later. </p>"},{"location":"identification/#option-2-pre-sorted-directories-existing-database","title":"Option 2: Pre-sorted Directories (Existing Database)","text":"<p>If you have an existing database organized by folders (where folder name = identity name), upload a ZIP with that exact structure.</p> <p>Structure Example:</p> <pre><code>upload.zip\n\u251c\u2500\u2500 Bastien/\n\u2502   \u251c\u2500\u2500 image1.jpg\n\u2502   \u251c\u2500\u2500 image2.jpg\n\u2502   \u2514\u2500\u2500 video1.mp4\n\u251c\u2500\u2500 Luna/\n\u2502   \u251c\u2500\u2500 image1.png\n\u2502   \u2514\u2500\u2500 image2.jpg\n\u2514\u2500\u2500 Max/\n   \u251c\u2500\u2500 video1.webp\n   \u2514\u2500\u2500 video2.mp4\n</code></pre>"},{"location":"identification/#option-3-advanced-metadata-import-csvxlsx","title":"Option 3: Advanced Metadata Import (CSV/XLSX)","text":"<p>For complex imports including locations, dates, and coordinates, include a <code>metadata.csv</code> or <code>.xlsx</code> file in the root of your ZIP archive.</p> <p>Structure Example:</p> <pre><code>upload.zip\n \u251c\u2500\u2500 imgs/\n \u2502   \u251c\u2500\u2500 im1.jpg\n \u2502   \u2514\u2500\u2500 im2.jpg\n \u251c\u2500\u2500 video1.mp4\n \u2514\u2500\u2500 metadata.csv\n</code></pre> <p>Metadata Format:</p> <code>original_path</code> <code>predicted_category</code> <code>unique_name</code> <code>locality name</code> <code>latitude</code> <code>longitude</code> <code>datetime</code> imgs/im1.jpg Lynx lynx Bastien Pod dubem 49.28021 13.1819 2023-10-01 14:30:00 imgs/im2.jpg Lynx lynx Luna Za kopcem 49.27921 13.8219 2023-10-01 15:00:00 video1.mp4 Lynx lynx Bastien Pod dubem 49.28031 13.1819 2023-10-01 16:00:00 <ul> <li><code>original_path</code>: Required. Path to file inside the ZIP.</li> <li><code>unique_name</code>: Optional. The ID of the animal (if known).</li> <li><code>predicted_category</code>: Optional. The species (e.g., Lynx lynx).</li> </ul>"},{"location":"identification/#updating-existing-metadata","title":"Updating Existing Metadata","text":"<p>You can also use the spreadsheet upload to batch-update metadata for files that are already in the system. Use the \"Update metadata\" option in the upload menu. </p>"},{"location":"identification/#2-the-dashboard","title":"2. The Dashboard","text":"<p>Once data is uploaded, you manage the workflow from the Identification Dashboard.</p> <p></p> <p>The dashboard provides an overview of:</p> <ul> <li>Active Tasks: Images currently being processed by the AI worker.</li> <li>Review Queue: Images processed by AI that are waiting for human confirmation.</li> <li>Identified Stats: Statistics on identified individuals.</li> </ul>"},{"location":"identification/#3-identification-review-process","title":"3. Identification &amp; Review Process","text":"<p>The AI suggests matches, but the final decision is yours. This ensures high data quality.</p>"},{"location":"identification/#selecting-images-for-review","title":"Selecting Images for Review","text":"<p>When you click Confirm Identification, you are presented with a list of images that have been processed by the identity analysis and have an embedding vector generated.</p> <p></p> <p>These images are sorted by AI confidence (the system's certainty about its top match). This allows you to prioritize the most certain identifications or focus on the difficult ones first. You can pick any image from this list to begin the matching process.</p>"},{"location":"identification/#the-matching-interface","title":"The Matching Interface","text":"<p>When you select an image from the list, the Matching Interface opens. This is where the side-by-side comparison happens.</p> <p></p> <p>The interface is divided into two main parts: *   Query Image (Left): The new, unidentified image. *   Candidates (Right): A ranked list of potential matches already existing in the database.</p>"},{"location":"identification/#how-to-process-a-match","title":"How to process a match:","text":"<ol> <li>Analyze the Suggestion: The system ranks candidates by similarity.</li> <li>Visual Comparison: Compare patterns, scars, or unique features between the Query Image and the Candidates.</li> <li>Confirm Identity:<ul> <li>Match Found: If you see the correct individual in the list, click the Confirm (or checkmark) button next to that candidate.</li> <li>No Match (New Individual): If the animal is not in the list, select the option to Create New Identity. You will be asked to name the new individual.</li> <li>Unidentifiable: If the image is too blurry or ambiguous, you can mark it as \"Unidentifiable\".</li> </ul> </li> </ol>"},{"location":"identification/#post-identification","title":"Post-Identification","text":"<p>Once confirmed, the image is added to that individual's gallery. This improves the AI's ability to recognize that specific animal in future uploads.</p>"},{"location":"install/","title":"Installation","text":"<p>This app is designed to be run via Docker Compose.</p>"},{"location":"install/#prerequisites","title":"Prerequisites","text":"<ul> <li>Git</li> <li>Docker Engine + Docker Compose v2 (<code>docker compose ...</code>)</li> <li><code>wget</code> and <code>unzip</code> (to fetch the NiceAdmin frontend assets)</li> </ul>"},{"location":"install/#1-clone-the-repository","title":"1. Clone the repository","text":"<pre><code>git clone https://github.com/WildlifeDatasets/wildlife-reid-app.git\ncd wildlife-reid-app\n</code></pre>"},{"location":"install/#2-create-env-with-required-secrets","title":"2. Create <code>.env</code> with required secrets","text":"<p>Create a <code>.env</code> file in the repository root and add the required variables:</p> <pre><code>echo \"WANDB_API_KEY=...\" &gt;&gt; .env\necho \"ALLAUTH_GOOGLE_CLIENT_ID=...\" &gt;&gt; .env\necho \"ALLAUTH_GOOGLE_CLIENT_SECRET=...\" &gt;&gt; .env\necho \"CAID_HOST=147.228...\" &gt;&gt; .env\n</code></pre> <p>The README also exports <code>CAID_HOST</code> in the shell (optional, depending on your workflow):</p> <pre><code>export CAID_HOST=\"147.228...\"\n</code></pre>"},{"location":"install/#optional-import-directory","title":"Optional: import directory","text":"<p>Optionally, add an import directory variable:</p> <pre><code>echo \"CAID_IMPORT=/mnt/caid_import\" &gt;&gt; .env\n</code></pre> <p>(Adjust paths to your environment.)</p>"},{"location":"install/#3-download-and-install-niceadmin-static-assets","title":"3. Download and install NiceAdmin static assets","text":"<p>The repository expects NiceAdmin assets under <code>src/api/static/</code>:</p> <pre><code>wget https://bootstrapmade.com/content/templatefiles/NiceAdmin/NiceAdmin.zip\nunzip NiceAdmin.zip\nmkdir -p src/api/static\nmv NiceAdmin/assets src/api/static/\n</code></pre>"},{"location":"install/#4-run-in-development-mode","title":"4. Run in development mode","text":"<p>Build and start using the development compose file:</p> <pre><code>docker compose -f docker-compose.dev.yml build\ndocker compose -f docker-compose.dev.yml up\n</code></pre> <p>To see the fully expanded compose configuration:</p> <pre><code>docker compose -f docker-compose.dev.yml config\n</code></pre>"},{"location":"install/#5-first-time-setup-django-admin-db","title":"5. First-time setup (Django admin + DB)","text":""},{"location":"install/#create-a-superuser","title":"Create a superuser","text":"<pre><code>docker exec -it carnivoreid-app-dev-api bash -ic 'python manage.py createsuperuser'\n</code></pre> <p>After that, in the admin panel:</p> <ul> <li>Create a new Workgroup</li> <li>Then, in <code>ciduser</code>, add this workgroup to the user</li> </ul>"},{"location":"install/#if-needed-make-migrations-and-migrate","title":"(If needed) Make migrations and migrate","text":"<pre><code>docker exec -it carnivoreid-app-dev-api bash -ic 'python manage.py makemigrations'\ndocker exec -it carnivoreid-app-dev-api bash -ic 'python manage.py migrate'\n</code></pre>"},{"location":"install/#6-run-tests","title":"6. Run tests","text":"<pre><code>docker compose -f docker-compose.dev.yml exec api_dev python manage.py test\n</code></pre>"},{"location":"install/#7-sample-data-optional","title":"7. Sample data (optional)","text":"<p>To add sample data:</p> <ul> <li>Create an <code>ArchiveCollection</code> named <code>sample_data</code></li> <li>Select multiple <code>UploadedArchive</code> instances and add them into that collection</li> </ul>"},{"location":"install/#license-note","title":"License note","text":"<p>This project uses Annotorious, licensed under the BSD 3-Clause License.</p>"},{"location":"taxon_classification/","title":"Taxon classification","text":"<p>The taxon classification is available from the dashboard. The main view gives you the access to most important functions.</p> <p>Users typically collect data by retrieving image data from a camera trap after a certain period of time.  The first step is then to sort the images by animal species.  As input for automatic species recognition, we expect a ZIP archive containing data from a single camera trap.  The user only needs to confirm or provide the camera trap location.  The classification of animal species in the images is carried out automatically.  The output is a ZIP archive containing the input data organized into folders by species and a CSV file with metadata (such as date/time the image was taken, identified species, etc.).</p> <p></p>"},{"location":"taxon_classification/#data-upload","title":"Data upload","text":"<p>The user can upload a ZIP archive containing images from a camera trap. The recommended naming  contain the date of camera trap check and the name of the locality.</p> <p></p> <p>When the upload is finished, the taxon classification is started automatically.</p> <p></p>"},{"location":"taxon_classification/#upload-using-synology-drive-client","title":"Upload using Synology Drive client","text":"<p>There is the possibility to upload multiple ZIP archives at once using the Synology Drive client. Let us know if you are interested in this feature.</p> <p>When the setup is done in cooperation with the administrator, there is a synchronized folder in the user computer. All ZIP archives in this folder are automatically visible in the Cloud upload section of the application. The file format require to combine the date of camera trap check and the name of the locality in the file name.</p> <p></p> <p>In the figure above, the user can see the files that are in the folder. The first one will be processed  without any problems, the second one contains unknown locality (which will be automatically added to the database during upload), and the third one will be skipped because the file name is not in correct format.  User can change the file name in the shared directory and reload the page to see the changes.</p> <p>There are three options to attach the locality and the date information to the zip file.  * The file name contains the date and the locality name. The date is in the format YYYY-MM-DD. * The synchronized directory contains a dir with the locality name. The files in this directory are named according to the date format YYYY-MM-DD. * The synchronized directory contains a dir with the date in the format YYYY-MM-DD. The files in this directory are named according to the locality name.</p> <pre><code>shared_dir/\n\u251c\u2500\u2500 2023-10-01/\n\u2502   \u251c\u2500\u2500 Locality1/\n\u2502   \u251c\u2500\u2500 Locality2/\n\u2502   \u2514\u2500\u2500 Locality3/\n\u251c\u2500\u2500 2023-10-02/\n\u2502   \u251c\u2500\u2500 locality1/\n\u2502   \u2514\u2500\u2500 locality3/\n\u2514\u2500\u2500 Locality2/\n    \u251c\u2500\u2500 2023-07-01/\n    \u2514\u2500\u2500  2022-10-01/\n</code></pre> <p>When the files are in the correct format, the user can click on the \"Import all\" button. The taxon classification will be started automatically.</p> <p>The other buttons can be used for the identification workflow. In the case the all files contains the same taxon, the user can click on the \"Import as single taxon\". If there exists a database of the identities, it can be imported using the \"Import all as known identity\" button.</p>"},{"location":"taxon_classification/#camera-trap-checks","title":"Camera trap checks","text":"<p>Each uploaded archive is considered as a camera trap check. The user can see the list of all camera trap checks in the application.</p> <p></p>"},{"location":"taxon_classification/#set-missing-taxa","title":"Set missing taxa","text":"<p>The taxa classification is started automatically after the upload is finished. Usually, the classification is missing in some media files. The user can set the missing taxa. It can be started from the Taxon classification view or from the Camera trap check view.</p> <p></p> <p>The media files with missing taxa are displayed. The user can select the taxa from the list or use the preselection based on the most probable taxa.</p>"}]}